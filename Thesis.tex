\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{natbib}
\usepackage{algorithm}
\usepackage{algpseudocode}

\newcommand{\mathDef}{\overset{\textit{def}}{=}}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true, %set true if you want colored links
    linktoc=all,     %set to all if you want both sections and subsections linked
    linkcolor=black,  %choose some color if you want links to stand out
}

\theoremstyle{definition}

\newtheorem{definition}{Definition}[section]
\newtheorem*{remark}{Remark}

\begin{document}

\tableofcontents
\newpage

\section{Super-peer Node}


An \textit{end-user} represents, instead, a third-party application that wants execute  one or more function choreographies.

\section{Peer Node}

Proposed 

Hybrid structures are notably deployed in collaborative distributed systems.
The main issue in many of these systems is to first get started, for which often
a traditional client-server scheme is deployed. Once a node has joined the
system, it can use a fully decentralized scheme for collaboration.


Relating to a specified function choreography $X$ belonging to resource owner $R$, a peer $P$ of our system can be in one of the following states:

\begin{description}
\item[Active State] When $P$ has been marked as responsible for manage all invocation requests of $X$ forwarded by end users.
\item[Forwarder State] Otherwise
\end{description}


function choreographies (FCs) or workflows of
functions. 

As known, in server-less computing platforms, computation is done in \textbf{function instances}. These instances are completely managed by the server-less computing platform provider (SSP) and act as tiny servers where a function is been executed.


\section{Resources}





\section{System's resources and actors}

\subsection{Resource owner}

A \textit{resource owner}, henceforward denoted with $R$, represents an entity capable of \textit{creating}, \textit{modifying} and \textit{authorizing} access to several resources of our system.

Given a resource owner $R$, there are two type of resources which he can manage:

\begin{enumerate}
\item Function choreographies.
\item Server-less function implementations (also called \textit{concrete server-less functions})
\end{enumerate}

\subsection{Function choreographies}

A \textit{function choreography} is the most important resource of our system and it is used to model both server-less functions and server-less function compositions.

Informally, it represents, using graph notation, all paths that might be traversed through a server-less function composition during its execution. In other words, it describes calling relationships between server-less functions.

Formally, being $R$ the resource owner, a \textbf{function choreography}, denoted as $FC_R$, is a \textit{control-flow graph} $G(V,E)$, where:

\begin{itemize}
\item Each node $v \in V$, called \textit{abstract control-flow node}, represents a generic function of a computer program.
\item Each edge $(v_i, v_j) \in E$, for any $i,j \in \mathbb{N}$ with $i \neq j$, indicates that the generic function $v_i$ calls that in $v_j$.
\end{itemize} 

Any function choreography can be  uniquely identified by an ordered string pair $(a, b)$, where $a$ is the \textit{resource owner name} while $b$ is the \textit{function choreography name}.

There are two types of abstract control-flow nodes:

\begin{description}
\item[Abstract server-less function] denoted as $f_{(abstract, i)}$ while the set of all server-less functions is denoted as $F_{abstract}$.
\item[Control-flow function] denoted ad $c_t$ while $C$ is the corresponding set of all control-flow functions.
\end{description}

Formally, let $|V| = n$, $|F_{abstract}| = t$, and $|C| = k$, where $t,k \in \mathbb{N}$ with $t + k = n$, we have that:

\begin{equation}
\begin{array}{lll}

V & \mathDef & F_{abstract} \cup C \\
  & = & (f_{(abstract, 1)}, \ldots, f_{(abstract, t)}) \cup (c_1, \ldots, c_k) \\
\end{array}
\end{equation}

Clearly, we said that function choreography models a server-less function, when $|V| = 1$ and $|E| = 0$; conversely, it models a server-less function composition, when $|V| > 1$ and $|E| > 0$.

\subsubsection{Abstract server-less function}

An \textit{abstract server-less function} represents a descriptions of one or more corresponding concrete server-less function implementations. That description includes:

\begin{itemize}

\item TODO
\item TODO
\item TODO

\end{itemize}

Any abstract server-less function can be uniquely identified by an ordered string pair $(a, b)$, where $a$ is the \textit{resource owner name} while $b$ is the \textit{abstract server-less function name}.

\subsubsection{Concrete server-less function}

Given an abstract server-less function, a resource owner can provide different implementations which, although they must be semantically equivalent, may eventually expose different performance or cost behaviour.

Therefore, we call \textit{concrete server-less function} any implementation of a given abstract function and it is uniquely identified by an ordered string tuple $(a, b, c)$, where $a$ and $b$ represent, like before, the \textit{resource owner name} and the \textit{abstract function name} respectively, while $c$ represents the so-called \textit{function type}, which is an abstract descriptions of the corresponding function implementation.

\subsubsection{Control-flow operator}

Like \texttt{if}, \texttt{for}, etc.

\subsection{Server-less function swarms}

Informally, a so-called \textit{server-less function swarm} represent a set of concrete server-less function with very specific properties.

Precisely, let $l \in \mathbb{N}$ such that $l \neq 0$, $R$ a resource owner, $P$ a server-less computing platform provider and  $X_R$ a set of concrete server-less functions. Moreover, let $\textbf{X}_R$ the set containing all concrete function implementations defined and deployed by $R$ on any provider. 

A set $X_R \subseteq \textbf{X}_R$ is called a \textit{server-less function swarm}, or simply \textit{swarm}, if:

\begin{enumerate}
\item $|X_{R}| = n \geq 1$, that is $X_{R}$ must contain at least one concrete function.
\item $X_{R}$ contain concrete functions that share the same platform provider $P$ where they will be executed.
\item $X_{R}$ contain concrete functions that share the same limit $l$ in term of max number of server-less function instance runnable at the same time by the corresponding platform provider $P$. That limit is also called \textit{server-less function swarm's concurrency limit}, or simply, \textit{concurrency limit}. 
\end{enumerate}

Is very important to make clear that only at most $l$ concrete functions belonging to $X_R$ can be executed simultaneously by $P$. The value of $l$ depends by specific policies adopted by $P$; some of them imposed that limit \textit{per-account}, others \textit{per-functions}. Our model supports both approaches because:

\begin{itemize}

\item If $P$ imposed limits \textit{per-function}, then $|X_{R}| = 1$, that is, $X_{R}$ will contain only one function defined and deployed by $R$ in $P$, where $l$ will be represent the provider's per-function limit.

\item If $P$ imposed a limit \textit{per-account}, then generally $|X_{R}| \geq 1$ and it include all concrete server-less function deployed on $P$ while $l$ will be represent the provider's global limit. 
\end{itemize}

\subsubsection{Server-less function sub-swarms}

A sub-swarm of ${X_{R}}$, which we will denote with $\Delta_{X_{R}}$, is the term with which we denote any element belong to the power set\footnote{The \textit{power set} $\mathcal{P}(S)$ of a set $S$ is the set of all subsets of $S$, including the empty set and $S$ itself.} of $X_{R}$, excluding the empty set. Formally, any $\Delta_{X_{R}} \in \mathcal{P}(X_{R}) \setminus \oslash$ is a sub-swarm.

Is very important to remember that in our model any sub-swarm $\Delta_{X_{R}}$ of ${X_{R}}$ has the \textit{same} concurrency limit of ${X_{R}}$.

\section{Function choreography scheduler}

\subsection{Schedulability condition}

Let $FC_R$ a function choreography belonging to a resource owner $R$ and $F_{abstract}$ its server-less abstract functions set. Moreover, be $\textbf{X}_R$ the set containing all functions deployed by $R$ in any provider.

In order to effectively start the execution of a function choreography, is required that for each abstract function $f_{abstract} \in F$ \textit{at least one} concrete function $f$, which implements it, exists.

Formally, a function choreography is said \textit{schedulable} when: 
\begin{equation}
\label{eqn:SchedulabilityConditionOne}
\begin{array}{lc}

& \forall f_{abstract} \in F_{abstract} \\

FC_R \text{ is schedulable } \Leftrightarrow & \\
 & \exists f \in \textbf{X}_R \mid  f \text{ implements } f_{abstract} \\
\end{array}
\end{equation}

Although it is correct, the condition expressed by equation \ref{eqn:SchedulabilityConditionOne} is not very precise, because $\textbf{X}_R$ can contain some functions that doesn't implement any $f_{abstract} \in F_{abstract}$.

Therefore, we define $\Omega_{FC_R}$ as the set containing only concrete functions that are needed to execute $FC_R$, which can both to belong to any provider and to have different concurrency limits.

Since multiple implementations of a same abstract function can exist at the same time, we can exploit the notion of swarm and sub-swarm to formally define the set $\Omega_{FC_R}$.

Let $n \in \mathbb{N}$, such that $n \geq 1$, and $X_{R_i}$ the $i$-th swarm and $\Delta_{X_{R_i}}$ its sub-swarm which contains only concrete functions implementing one or more $f_{abstract} \in F_{abstract}$, where $1 \leq i \leq n$.

We define $\Omega_{FC_R}$ as follows: 

\begin{equation}
\begin{array}{c}
\Omega_{FC_R} \mathDef \Delta_{X_{R_1}} \cup  \ldots \cup \Delta_{X_{R_n}} = \bigcup_{i = 1}^n \Delta_{X_{R_i}} \\

\text{ where } \\	

\Delta_{X_{R_i}} \cap \Delta_{X_{R_j}} = \oslash \quad \text{ for } i,j \in \left[ 0, n \right] \mid i \neq j \\

\forall f \in \Delta_{X_{R_s}} \quad f \text{ implements } f_{abstract} \text{ for } s \in \left[ 0, n \right] \\

\end{array}
\end{equation}

Since belong to different swarms, please note that any $\Delta_{X_{R_i}}$ and $\Delta_{X_{R_j}}$, for any $i \neq j$, can belong to the same provider but they cannot share the same concurrency limit.

Generally the schedulability condition for $FC_R$ can be written as follows:

\begin{equation}
FC_R \text{ is schedulable } \Leftrightarrow \exists \Omega_{FC_R}
\end{equation}


\subsection{The $\Delta_{X_{R}}$-Scheduler}

Let $R$ a resource owner, $P$ the server-less provider and $\Delta_{X_{R}}$ a sub-swarm of a $X_{R}$, where $k$ its concurrency limit.

Let $m \in \mathbb{N}$, a \textit{$\Delta_{X_{R}}$-Scheduler}, denoted as $S_{(\Delta_{X_{R}},m)}$ represents a queuing system, implementing any scheduling discipline, equipped with $m$ so-called \textit{virtual function instance}, where $m \leq k$.

Its aim is to decide when and which function, belonging to $\Delta_{X_{R}}$, must be performed on $P$. 

The parameter $m$ is also called \textit{scheduler capacity}.

\subsubsection{Virtual function instance}

A \textit{virtual function instance} represents a real function instances, clearly belonging to the server-less computing platform provider, which is \textit{virtually} owned by $S_{(\Delta_{X_{R}},m)}$.

Therefore, $m$ represents the max number of server-less function instances usable simultaneously by $S_{(\Delta_{X_{R}},m)}$.

\subsubsection{Proprieties and constrains}

According to our model, a $\Delta_{X_{R}}$-scheduler capable to manage any function belonging to $\Delta_{X_{R}}$, if exist, is \textit{not} unique, although it is unique inside a peer node. 

In order to achieve better performance in terms of network delay experienced by end users, fault tolerance and load balance, any peer nodes can hold a $\Delta_{X_{R}}$-scheduler in order to manage incoming request sent by several users spread in different geographic regions. 

However, despite there is no upper bound to the number of $\Delta_{X_{R}}$-schedulers existing at the same time in our system, there is a limitation regarding the scheduler capacity of each existing scheduler. 

Let's start summarizing all rules regarding $\Delta_{X_{R}}$-schedulers:

\begin{enumerate}

\item All peer node of our system can hold a $\Delta_{X_{R}}$-scheduler object.

\item Each node can hold only one instance of type $\Delta_{X_{R}}$-scheduler.

\item Let $n \in \mathbb{N}$ such that $n \geq 1$, suppose that our system contains $n$ peer nodes holding a $\Delta_{X_{R}}$-scheduler.

To be more precise, let's say that a sequence $S_{(1,(\Delta_{X_{R}},m_1))}, \ldots , S_{(i,(\Delta_{X_{R}},m_n))}$ exist at the same time in our system, where $S_{(i,(\Delta_{X_{R}},m_i))}$ represent the $\Delta_{X_{R}}$-scheduler owned by $i$-th node having scheduler capacity equal to $m_i$.

Following constraint must be hold:

\begin{equation}
\label{eqn:SchedulerConstrains}
\sum_{i=1}^{n} m_i \leq k
\end{equation}

where $k \in \mathbb{N}$, with $k > 0$, is the concurrency limit of the swarm $X_R$.

Remember that any sub-swarm $\Delta_{X_{R}}$ share the same concurrency limit of $X_R$. Therefore, equation \ref{eqn:SchedulerConstrains} states that, the sum of all scheduler capacities which manage the functions belonging to $\Delta_{X_{R}}$, must be less or equal to the max number of function instances executable at the same time on the server-less computing platform provider.

\end{enumerate}

\subsection{The $FC_R$-Scheduler}

To support hybrid-scheduling, that is the ability to execute multiple concrete function implementations belonging to different providers or subjected to different concurrency limit, in order to select the most suitable concrete function implementation according to a given QoS, unfortunately only one ``\textit{scheduler}" is not enough.

We call \textit{$FC_R$-Scheduler} a set of \textit{$\Delta_{X_{R}}$-Schedulers} where $\Delta_{X_{R}} \in \Omega_{FC_R}$. Is always required that $|FC_R| \geq 1$, that is, at least one scheduler must exist.

\section{$FC_R$-Active Peer Node}

According to our model, in order to effectively invoke all server-less concrete function belonging to a function choreography $FC_R$, is required that a peer node is ``active".

We said that a peer node $A$ is $FC_R$-\textit{active peer node}, or, simply, \textit{active}, when it holds a $\Delta_{X_{R}}$-scheduler for any sub-swarm in $\Omega_{FC_R}$. Formally:

\begin{equation}
A \text{ is } FC_R\text{-active peer node } \Leftrightarrow \forall \Delta_{X_{R}} \in \Omega_{FC_R} \quad \exists S_{(\Delta_{X_{R}},m)} \text{ hold by } A
\end{equation}

Multiple nodes can be active at the same time. Any node perform its scheduling decision independently.


\section{Architecture overview}

Our system design is based on a network of nodes, or \textit{peers}, every of which has the \textit{same functionality}; in fact, any of them is able to handle request submission, request scheduling and, potentially, request execution. 

This is the reason according to which we can mark our proposal as a \textit{P2P system}.

\subsection{Overlay network}

Our system's nodes are connected by an \textit{overlay network}.

\begin{definition}[Overlay network]
An overlay network is a virtual network built on top of a physical network according to which each nodes can communicate with other if and only if they are connected by virtual links belonging to the virtual network. 
\end{definition}

\begin{remark}
A node may not be able to communicate directly with an arbitrary other node although they can communicate through physical network.
\end{remark}

To be more precise, we have adopt a fully \textit{centralized unstructured overlay network} because the \textit{peer-resource index}, sometimes called \textit{directory}, is centralized. 

Please note that hybrid unstructured or fully decentralized solutions are technically possible, but guarantees about quality of service are very difficult.

\subsubsection{Locality-awareness property}

\textit{Locality-awareness} is one of the essential characteristics of our system. In fact, if each peer is able to select his neighbours exploiting a suitable locality aware algorithm, is possible to decrease user experienced delays.

We have decided to adopt a multi-level based locality-aware neighbour selection called \textit{intra-AS lowest delay clustering algorithm} (ASLDC). 

When ASLDC algorithm is used, each peer chooses nearby peers only from those within the same AS; then it ranks its neighbours in terms of transmission latency, preferring to o establish the connection with the node with the shortest latency to itself. 

TODO \cite{UnderstandingLocalityAwareness}

\subsection{Fault Tolerance}

Like in many other P2P implementation, there are two ways of detecting failures in our proposed solution:

\begin{enumerate}
\item If a node tries to communicate with a neighbour and fails.
\item Since all nodes send to all his neighbour nodes so-called ``heartbeat" messages, that is messages sent at fixed time intervals to indicate that the sender is alive, is possible to detect a failure by not receiving aforementioned periodic update messages after a long time. 

\end{enumerate}

\subsubsection{Availability}

Let $n \in \mathbb{N}$, $R$ a resource owner and $FC_R$ his function choreography, since multiple $FC_R$-Scheduler object can exist in $n$ different nodes, our proposed solution can guarantee an high degree of availability. 

In fact, when a node node holding an $FC_R$-Scheduler fails, all end users requests related to $FC_R$ can be routed to any other node holding a $FC_R$-Scheduler. 

\subsubsection{Replication}

Although multiple $FC_R$-Scheduler object can exist, it's not mean that $FC_R$-Scheduler object are replicated, because every of them manage different virtual function instances. 

Except the peer-resource index, any form of replication is performed by our system.







\begin{algorithm}
\caption{An algorithm with caption}\label{alg:cap}
\begin{algorithmic}

\State $y \gets 1$


\end{algorithmic}
\end{algorithm}




 and $\Delta_{X_{R}}$-Scheduler








The locality awareness of the overlay network is used in scheduling jobs, described in Section 3.2







physical network but with added properties such as fault tolerance and flexibility. 











The first problem is scheduling. Since there
is no central scheduler it is difficult



Hybrid unstructured overlay


\subsection{$FC_R$-Request}







 object with only one limitation:

Suppose that globally there are a set of schedulers $S_{1,({R_{X}},m_1)}, \ldots , S_{p,({R_{X}},m_p)}$, where $p \in \mathbb{N}$ with $p \geq 1$



To be more precise, when a function $x_j$ must to be execute, let $s$ the current number of busy virtual instances, one of the following events may occur:
\begin{enumerate}
\item if $s < m$, the scheduler invoke directly the function $x_j$ on the provider.
\item if $s = m$, the scheduler delay the execution of the function $x_j$ on the provider according to implemented scheduling discipline.
\end{enumerate}








Let $R$ a resource owner and $R_x$ its function choreography made up of $R_{x_1}, R_{x_2}, \ldots, R_{x_n}$ unique server-less functions; it is said that a peer node $P$ is \textbf{responsible} for $R_x$ when it contains a sequence of schedulers $S_{R_1}, S_{R_2}, \ldots, S_{R_k}$ with $k \leq n$, belonging to $R$, capable to invoke all server-less function belonging to $R_x$. 

It is said that a 

Depending on the definition of the function choreography provided by $R$ and the unique characteristics of back-end server-less providers which execute all serverless functions $R_{x_n}$ of 




It is said that a scheduler $S$ is capable to invoke a server-less function when 
, a scheduler $S$ can invoke multiple




When a peer $A$, placed ``\textit{at the edge}" of the network, receives a new request of invocation for $X$ by an end user, it performs following task in that order:

\begin{enumerate}
\item If it responsible It check for it is an already an \textit{active peer} to manage 
\end{enumerate}




 has found the tracker for a file F, the tracker returns a subset
of all the nodes currently involved in downloading F.




Replication and Fault Tolerance. There are two ways of detecting failures in CAN,
the first if a node tries to communicate with a neighbor and fails, it takes over that neighbor’s
zone. The second way of detecting a failure is by not receiving the periodic update message
after a long time. In the second case, the failure would probably be detected by all the
neighbors, and all of them would try to take over the zone of the failed node, to resolve this,
all nodes send to all other neighbors the size of their zone, and the node with the smallest
zone takes over.

\newpage


\begin{equation}
E[T] = \sum_{i = 0}^n E[S_i] + E[T_{Q_i}]
\end{equation}

\section{Queuing system of a $\Delta_{X_{R}}$-scheduler}

Let $k \in \mathbb{N}$ such that $k \geq 0$. Moreover, suppose that $R$ represents a resource owner, $P$ a server-less provider and $\Delta_{X_{R}}$ a sub-swarm of the swarm $X_{R}$ where $k$ its concurrency limit. Finally, let $S_{(\Delta_{X_{R}},m)}$ a $\Delta_{X_{R}}$-scheduler. 

Obliviously, since there are only $m$ available virtual function instances, if there are more than $m$ server-less functions waiting to be execute, a choice has to be made about which server-less function has to run next to ensuring QoS guarantees for latency critical applications.

Because we expect to execute server-less functions with different response-time requirements, which may have different scheduling needs, i have designed the $\Delta_{X_{R}}$-scheduler as a queuing system implementing a \textit{multilevel queue scheduling algorithm} which partitions the ready queue into several separate queues. 

According to our solution, each queue has its own scheduling algorithm and any server-less function is permanently assigned to one queue according to his class.

In addition, we have adopt \textit{round-robin} (\textit{RR}) scheduling algorithm to perform scheduling activity among the queues.

\subsection{Server-less function preemption}

A very important consideration regards server-less function preemption. 

In our context, due to FaaS paradigm, which hides the complexity of servers where our functions will be executed, the ability to preempt functions is not naturally available.

For that reason, only non-preemptive scheduling algorithms, according to which once a server-less function starts running it cannot be preempted, even if a higher priority server-less function comes along, can be adopted.

Since many scheduling algorithms require job preemption to run optimally, this situation can lead to a suboptimal resource management. 

\subsection{Queuing system design}

A $\Delta_{X_{R}}$-scheduler is made up of three queues:

\begin{itemize}

\item One queue implements a \textit{Non-Preemptive Least-Slack-Time-First} (\textit{LST}) scheduling algorithm. We will refer to that queue using $Q_{LST}$ notation.

That algorithm implements a \textit{dynamic priority scheduling approach} where priorities are assigned to server-less functions based on their \textit{slacks}.

At any time $t$, the \textit{slack} of a job with deadline at $d$ is equal to $d - t - s$, where $s$ is the time required to complete the job. 

Any job having strict latency requirements must to be assign to this queue.

\item Another queue implements, instead, a \textit{Non-Preemptive Shortest-Job-First} (\textit{SJF}) scheduling algorithm. That queue is denoted with $Q_{SJF}$.

That policy assigns priorities to jobs based on their size: the smaller the size, the higher the priority.

This queue is reserved for any function choreography that tolerates high latency. However, according to queueing theory, since SJF performs very bad when service time distribution is heavy-tailed; in fact

\begin{equation}
E[T_Q(x)]^{SJF} = \dfrac{\rho E[S^2]}{2E [S]} \cdot \dfrac{1}{(1 - \rho x )^2}
\end{equation}

This queue is not suitable for very, very large server-less function. The variance in the job size distribution must be low.

\item Finally, the third queue exploits the the simplest scheduling algorithm, that is the \textit{First-Come-First-Served} (\textit{FCFS}) policy, and it is denoted using $Q_{FCFS}$ notation.

This queue is used for any heavy-tailed server-less function which can tolerate high latency.
\end{itemize}

\subsection{The virtual function instances allocation problem}

Although a $S_{(\Delta_{X_{R}},m_A)}$ owns $m$ 




This form of aging prevents starvation. 


Finally, suppose that a node peer $A$ holds a $S_{(\Delta_{X_{R}},m_A)}$, which represents the 
$\Delta_{X_{R}}$-Scheduler object.

\begin{enumerate}
\item Once a request is received over HTTP
\item Ask to the coordinator for 
\end{enumerate}























\bibliography{Bibliography}
\end{document}