\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\author{Andrea Graziani}
\title{?}
\begin{document}

Ricordando che:

\begin{itemize}
\item The best synchronization technique consists in designing our system so as to avoid
the need for synchronization in the first place.
\end{itemize}

--------------------------------------------------------------

\section{Architettura generale}

\begin{itemize}
\item L'attività di scheduling \textbf{non} deve essere un'attività relegata ad un solo processo. Una architettura gerarchica del \textit{controller} non è sostenibile poiché:

\begin{itemize}
\item Non è scalabile orizzontalmente
\item Single point of failure
\item Traffico di rete intenso.
\end{itemize}



\item L'architettura del sistema sarà \textbf{flat} (\textbf{\textit{forse}} unstructured P2P).

\item Il resource owner è colui che crea e mette a disposizione le coreografie

\item Viene introdotto il concetto di responsabilità. Un nodo $A$ si dice \textbf{responsabile} delle attività di scheduling per le invocazioni delle composizioni/funzioni serverless associate al resource owner $X$, se contiene un processo (o thread) $p$, chiamato \textbf{processo scheduler}, che, avendo tutte le strutture dati necessarie e la conoscenza riguardo le composizioni di $X$, riesce a schedulare e gestire le invocazioni degli utenti delle composizioni di $X$.

\item \textbf{Non è necessaria alcuna forma di coordinazione tra i nodi riguardo le attività di scheduling}. Ogni processo scheduler in esecuzione nei vari nodi del sistema lavora indipendentemente (a prescindere da come lo implementiamo). 

\item In linea di principio deve esistere un \textbf{processo scheduler per ogni resource owner.} Più precisamente, se esiste almeno una richiesta di invocazione di una coreografia appartenente ad un resource owner $X$, deve esistere nel sistema un processo scheduler associato al resource owner $X$.

\begin{itemize}
\item Eventualmente, se non si registrano invocazioni di composizioni del resource owner $X$ per un "\textit{certo tempo}", è possibile deallocare le risorse associate e il nodo perde la responsabilità della g
\end{itemize}

\item I processi scheduler sono \textbf{RISORSE}. Hanno uno \textbf{STATO} e una \textbf{GUID} (univocamente identificabili a liello GLOBALE)!!!!

\item Quando un nodo A riceve una richiesta di esecuzione di una coreografia associata al resoruce owner X, se A è il responsabile delle risorse di X, ovvero contiene il processo scheduler di X, allora accoda la richiesta nello scheduler secondo l'algoritmo implementato.

\item Quando un nodo A riceve una richiesta di esecuzione di una coreografia associata al resoruce owner X, se A \textbf{NON} è il responsabile delle risorse di X, allora \textbf{ESEGUE UN LOOKUP per sapere chi è il responsabile e gli inoltra la richiesta.}

\begin{itemize}
\item Se il lookup da esito negativo, ovvero non esiste ancora un responsabile per X, il nodo che riceve la richiesta diventa automaticamente il responsabile. Quindi allocherà risorse per gestire la richiesta ricevuta.
\end{itemize}

\end{itemize}

\section{Migrazione degli scheduler}

\begin{itemize}
\item Per garantire bilanciamento del carico nel sistema, si dovrebbe fare in modo che ogni nodo gestisca un numero pressoché uguale di processi scheduler. Tuttavia, non essendo i processi tutti uguali (esisteranno delle differenze), i nodi dovrebbero supportare un numero equo di richieste.

\item I nodi \textbf{MENO} sovraccarichi hanno la facoltà di richiedere processi scheduler a nodi vicini. Se si accorge che un nodo vicino è particolarmente carico, richiede una migrazione. Un nodo non può richiedere la migrazione di un processo scheduler se tale processo è già sottoposto a migrazione da parte di un altro nodo. (DA VEDERE... NON E' DETTO CHE DEBBANO ESSERE I NODI MENO CARICHI A RICHIEDERE UNA MIGRAZIONE)

\item I processi scheduler hanno la facoltà di migrare da un nodo all'altro secondo due forme di necessità:
\begin{itemize}
\item Bilanciamento carico
\item Posizione geografica. Il processo scheduler associato alla gestione delle composizioni del resource owner X, dovrebbe essere posizionato "vicino" ai richiedenti!!
\end{itemize}

\item Per conoscere lo stato dei nodi vicini, è previsto l'uso di un protocollo di \textbf{GOSSIPING} (quello \textbf{probabilistico}) attraverso cui ogni nodo dovrebbe riuscire ad ottenere una \textbf{visione LOCALE} del sistema.

\item Ogni nodo agisce in modo PROATTIVO (con tutti gli svantaggi e i vantaggi del caso) per cui ad intervalli regolari e a bassa frequenza invia ai suoi vicini informazioni sul loro stato (GUID degli scheduler e numero delle richieste pendenti associate a ciasucna di esse che sta gestendo).

\begin{itemize}
\item In realtà, per ottimizzare la propagazione dell'informazione, supponiamo di avere i nodi A e B dove A è vicino al nodo C il quale non è vicino al nodo B.... in sostanza A inoltra anche le informazioni di B verso C.
\end{itemize}

\item Quando avviene una migrazione si da sempre priorità alla migrazione di processi scheduler aventi il MINOR NUMERO di richieste da processare presso il nodo. 

\item \textbf{Un nodo non può migrare un processo scheduler se ne ha uno solo.}

\item \textbf{Un nodo non può migrare un processo scheduler se la somma delle richieste che sta processando più quella delle richieste del processo scheduler in esecuzione sul nodo sovraccarico è simile a quella del nodo preso in esame anche se hanno meno processi scheduler}

\item E' una sorta di Information Sharing Pattern (??)
\end{itemize}

\section{Ulteriori possibilità alla Migrazione degli scheduler}

\begin{itemize}
\item Ogni nodo tiene traccia, in maniera totalmente indipendente, del numero di richieste 
associate alle risorse del resource owner X. Se viene a sapere che un nodo vicino possiede lo scheduler di X, richiede la migrazione di X presso di lui IN MODO DA OTTIMIZZARE IL DELAY DI RETE. (il PULL DEI PROCESSI SCHEDULER)

\item SI PRESUPPONE CHE OGNI NODO ABBIA UGUALI CARATTERISTICHE IN TERMINI DI POTENZA COMPUTAZIONALE E CHE VENGANO GESTITE DA UNA STESSA AUTORITY

\item LA MIGRAZIONE E DI TIPO IBRIDA. Il nodo di destinazione prima alloca tutte le risorse, DIVENTA IL RESPONSABILE, e SOLO DOPO incomincia a ricevere LE NUOVE richieste associate ad al resource owner X. Il vecchio nodo è tenuto a smaltire tutte le richieste prese in carico prima di deallocare tutte le risorse. Quando il vecchio nodo ha smaltito tutte le richieste si considera compiuta la migrazione tuttavia è possibile eseguire una nuova migrazione anche qualora quella precedente associata ad X non è stata completata. (PER ORA!!! NON NE SONO SICURO)

\item TUTTE LE informazioni NECESSARIE PER EFFETTUARE LO SCHEDULING DEVONO TROVARSI SUL NODO PRIMA DI DIVENTARE IL NUOVO RESPONSABILE (strutture dati, thread vari...)
\end{itemize}

\subsection{Migrazione dei "Processori" (o Migrazione di capacità) Proattiva}

\begin{itemize}
\item Ogni provider serverless impone un limite $n$ riguardante il numero di invocazioni.
che per noi è arbitrario. E' ragionevole aspettarsi che aumenti.

\item Se aumenta "troppo" il design precedente tende a sovraccaricare il nodo responsabile dello scheduler del resource owner di X.

\item L'idea quindi è implementare una forma di migrazione della capacità di calcolo a disposizione (o processori).

\item Possono esistere più nodi responsabili di X, ma la dimensione (o capacità) delle code che implementano i loro scheduler sono solo una frazione del totale ammesso dai provider.

\item Il problema del lookup quando arriva una nuova richiesta viene gestito in questo modo:
\begin{itemize}
\item Se il nodo di arrivo è responsabile di X, il nodo accetta la richiesta e la schedula.
\item Se non lo è, ed il QoS della richiesta è tempo di risposta, allora la inoltra al nodo responsabile più vicino (in termini di rete)

\item Se non lo è ed il Qos della richiesta è di tipo costo, allora la inoltra allo scheduler meno carico.
\end{itemize}

\item La migrazione di capacità avviene in modo \textbf{proattivo} tenendo conto del carico. \textbf{Idealmente, ogni nodo dovrebbe conservare uno storico delle richieste in tipo ed in quantità per richiedere ai nodi capacità e prepararsi ad un imminente picco di richieste}.
\end{itemize}



\section{Non c'è un singolo scheduler per \textit{resource owner}}

\begin{itemize}
\item Un \textit{resource owner} potrebbe usare implementazioni di composizioni appartenenti a differenti provider (lambda, IBM etc.). Ogni provider può gestire le funzioni serverless in modo diverso ed avere LIMITI diversi. (\textbf{tetto massimo di invocazione di funzioni globale VS tetto massimo di invocazioni per funzione})

\item Per riflettere ciò, ogni nodo gestisce esattamente un numero di processi scheduler, associati TUTTI ad un singolo resource owner, che è pari al numero di piattaforme supportate. (ESEMPIO: supporto IBM e AWS.. ogni nodo gestisce due processi scheduler per resource owner: uno per schedulare funzioni su IBM e l'altro su AWS... LE COMPOSIZIONI POSSONO AVERE TRANQUILLAMENTE IMPLEMENTAZIONI DI ENTRAMBI I PROVIDER)

\item Questo è vero se e solo se il resource owner usa effettivamente tutte le piattaforme supportate...PUOI AVERE ANCHE UN SOLO NODO.. PER CUI OGNI NODO GESTISCE UN NUMERO DI SCHEDULER PARI AL NUMERO DEI SERVIZI SERVERLESS EFFETTIVAMENTE UTILIZZATI dal resource owner.

\end{itemize}

\section{OTTIMIZZAZIONI}

\begin{itemize}
\item Per evitare di allocare strutture dati uguali ogni volta ad ongi invocazione di una corerografia si usano delle cache.

\item Ogni nodo a delle proprie cache ed agiscno in maniera indipendente.

\item C'è una cache per ogni processo scheduler.

\item lo scheduler è implementato con alberi splay (o forse AVL o B-TREE)

\item L'accesso alla cache è possibile solo da parte di un solo thread. Non è necessaria alcuna forma di sincronizzazione.
\end{itemize}

\section{Tolleranza ai guasti}

\begin{itemize}
\item Il design garantisce di per se Maggior tolleranza ai guasti

\item La tolleranza ai guasti dei nodi viene raggiunta attraverso uno schema simile a bittorent. In realtà dovremmo abbiamo dei cluster di nodi. Ogni cluster è il responsabile di X. Ogni cluster è organizzato gerarchicamente e, attraverso la elezione di un nodo leader (SUPERPEER), egli gestisce la computazione (POI replicazione attiva)

\item CI SONO ALTERNATIVE? (Certo che ci sono...forse i log?)
\end{itemize}


\section{Caratteristiche}

\begin{itemize}
\item Scalabile orizzontalmente.

\item NON E' UN'APPLICAZIONE EDGE-NATIVE MA EDGE-ACCELERATED (per ora...)

\item Elegante :) 

\end{itemize}

\section{PROBLEMI}


\begin{itemize}
\item Le informazioni sugli utenti e sulle coreografie sono CENTRALIZZATE su un cluster di zookeeper (CENTRALIZZATO)

\item L'OPTIMIZER è anche esso CENTRALIZZATO. ((E VA BENE COSì PER ORA)

\item come RISOLVERE IL LOOKUP?????????????????????? (CHORD????? \textbf{ma non va bene perché l'overlay non tiene conto della posizione geografica})  CONCETTO DI ULTRAPEER ??? (vedi bittorrent)
\end{itemize}

\end{document}